{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe3e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import EvalPrediction\n",
    "from setfit import SetFitModel, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b70cec",
   "metadata": {},
   "source": [
    "### Save the path to the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d022a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_path = \"./data_sources/train/train_en.csv\"\n",
    "test_en_path = \"./data_sources/test/test_en.csv\"\n",
    "\n",
    "train_it_path = \"./data_sources/train/train_it.csv\"\n",
    "test_it_path = \"./data_sources/test/test_it.csv\"\n",
    "\n",
    "train_es_path = \"./data_sources/train/train_es.csv\"\n",
    "test_es_path = \"./data_sources/test/test_es.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585c85e",
   "metadata": {},
   "source": [
    "### Set up W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c7e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msravisconti\u001b[0m (\u001b[33msravisconti-projects\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4fd9a",
   "metadata": {},
   "source": [
    "### Load data in DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35cca254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV manually for the train split\n",
    "train_df = pd.read_csv(train_it_path)\n",
    "test_df = pd.read_csv(test_it_path)\n",
    "\n",
    "# Convert back to Hugging Face Datasets\n",
    "dataset_it = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    \"test\": Dataset.from_pandas(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837c128",
   "metadata": {},
   "source": [
    "### Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a7661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, labels):\n",
    "    precision_macro = precision_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    recall_macro = recall_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"macro_f1\": f1_macro,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59388b56",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e5bf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Applying column mapping to the training dataset\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 868/868 [00:00<00:00, 11473.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>macro_f1</td><td>â–</td></tr><tr><td>precision_macro</td><td>â–</td></tr><tr><td>recall_macro</td><td>â–</td></tr><tr><td>train/embedding_loss</td><td>â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ƒâ–‚â–â–â–â–ˆâ–„â–‚â–â–â–â–‡</td></tr><tr><td>train/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–â–‚â–‚â–ƒâ–„â–…â–†â–ˆâ–â–‚â–…â–†â–</td></tr><tr><td>train/global_step</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒ</td></tr><tr><td>train/grad_norm</td><td>â–„â–ƒâ–ƒâ–â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–â–â–â–†â–†â–‚â–â–â–â–â–ˆ</td></tr><tr><td>train/learning_rate</td><td>â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–†â–„â–ƒâ–ƒâ–ƒâ–‚â–…â–ˆâ–„â–ƒâ–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>macro_f1</td><td>0.87399</td></tr><tr><td>precision_macro</td><td>0.85735</td></tr><tr><td>recall_macro</td><td>0.89448</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/embedding_loss</td><td>0.2801</td></tr><tr><td>train/epoch</td><td>0.00092</td></tr><tr><td>train/global_step</td><td>1</td></tr><tr><td>train/grad_norm</td><td>3.23317</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train_loss</td><td>0.03405</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">setfit-it</strong> at: <a href='https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline/runs/oa7agbhr' target=\"_blank\">https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline/runs/oa7agbhr</a><br> View project at: <a href='https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline' target=\"_blank\">https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_001331-oa7agbhr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sravi\\Desktop\\Projects\\multi-pride\\.venv\\Lib\\site-packages\\wandb\\analytics\\sentry.py:263: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sravi\\Desktop\\Projects\\multi-pride\\wandb\\run-20251118_113513-nwx9e4cq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline/runs/nwx9e4cq' target=\"_blank\">setfit-it</a></strong> to <a href='https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline' target=\"_blank\">https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline/runs/nwx9e4cq' target=\"_blank\">https://wandb.ai/sravisconti-projects/multi-pride-setfit-pipeline/runs/nwx9e4cq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 8680\n",
      "  Batch size = 8\n",
      "  Num epochs = 2\n",
      "c:\\Users\\sravi\\Desktop\\Projects\\multi-pride\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2170' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2170/2170 1:30:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sravi\\Desktop\\Projects\\multi-pride\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Applying column mapping to the evaluation dataset\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'precision_macro': 0.8738624873609707, 'recall_macro': 0.9001623376623377, 'macro_f1': 0.8861024033437827}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SetFitModel.from_pretrained(model_name)\n",
    "\n",
    "# to match labels with meaning: 0 --> \"offensive\", 1 --> \"reappropriative\"\n",
    "model.labels = [\"offensive\", \"reappropriative\"]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    batch_size=8,\n",
    "    num_epochs=2,\n",
    "    num_iterations=5,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset_it[\"train\"],\n",
    "    metric=compute_metrics,\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"}\n",
    ")\n",
    "\n",
    "wandb.init(project=\"multi-pride-setfit-pipeline\", name=\"setfit-it\")\n",
    "\n",
    "trainer.train()\n",
    "final_results = trainer.evaluate(dataset_it[\"test\"])\n",
    "wandb.log(final_results)\n",
    "print(\"Final test metrics:\", final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12373ab5",
   "metadata": {},
   "source": [
    "### Metric Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6262d864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      offensive       0.97      0.94      0.95       176\n",
      "reappropriative       0.78      0.86      0.82        42\n",
      "\n",
      "       accuracy                           0.93       218\n",
      "      macro avg       0.87      0.90      0.89       218\n",
      "   weighted avg       0.93      0.93      0.93       218\n",
      "\n",
      "Confusion Matrix:\n",
      "                       Pred: offensive  Pred: reappropriative\n",
      "True: offensive                    166                     10\n",
      "True: reappropriative                6                     36\n"
     ]
    }
   ],
   "source": [
    "# Mapping label strings -> integers\n",
    "label2id = {label: i for i, label in enumerate(model.labels)}\n",
    "\n",
    "# Get raw predictions from SetFit (strings)\n",
    "raw_preds = trainer.model.predict(dataset_it[\"test\"][\"text\"])\n",
    "\n",
    "# Convert to integers\n",
    "y_pred = np.array([label2id[p] for p in raw_preds])\n",
    "\n",
    "y_true = np.array(dataset_it[\"test\"][\"label\"])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=model.labels\n",
    "))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "cm_df = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred),\n",
    "    index=[f\"True: {label}\" for label in model.labels],\n",
    "    columns=[f\"Pred: {label}\" for label in model.labels]\n",
    ")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1efc0",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e910383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted offensive but actually reappropriate:\n",
      "\n",
      "0\n",
      "Che branco di guardoni morbosi, â€œfruga-mutandeâ€ della sessualitÃ  altrui, della vita altrui, degli amori altrui, câ€™Ã¨ al mondo. Mi dispiace, @USER ğŸ¤\n",
      "\n",
      "â€œAncor prima di ammetterlo a me stesso, io ero un ricchione, e questo andava scritto, ripetuto, urlato - soprattutto sussurratoâ€\n",
      "\n",
      "\n",
      "1\n",
      "chi pensa che il problema sia l'omofobia Ã¨ IL problema. voglio perÃ² dire frocio quando mi pare solo perchÃ© mi piace la parola. FROCIO. sono omofobo? lol l'unica cosa che mi spaventa Ã¨ il vaccino ago bua. voglio urlarlo: VIVA I FROCI, lunga vita a loro, quindi a me\n",
      "\n",
      "\n",
      "2\n",
      "@USER @USER Per qualcuno sono gay,per altri transgender, per latri ancora LGBT. Per so froci e rottinculo! Bloccatemi vigliacchi di Twitter\n",
      "\n",
      "\n",
      "3\n",
      "@USER non sono fiduciosa negli spazi di aggregazione online. Letteralmente ci sono i queer frocialisti eccetera eccetera e poi i circoletti di gay che postano nudes ogni giorno hanno onlyfans e sono convinti di vivere in un porno 24/7\n",
      "\n",
      "Ã¨ un incubo\n",
      "\n",
      "\n",
      "4\n",
      "@USER Ha votato una persona che nega i miei diritti da frocio â€¦ la cosa Ã¨ totalmente diversa da simpatia o gusti del gelato\n",
      "\n",
      "\n",
      "5\n",
      "Sono frocio ma - a differenza sua che guarda solo il suo orticello - supporto i diritti delle donne sex workers che vogliono aprirsi un account onlyfans.\n",
      "\n",
      "E supporto ovviamente anche le donne che non vogliono aprirsi un account onlyfans.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indices of false positives : predicted offensive but actually reappropriate\n",
    "fn_indices = np.where((y_true == 1) & (y_pred == 0))[0]\n",
    "\n",
    "fn_sentences = [dataset_it[\"test\"][i]['text'] for i in fn_indices]\n",
    "\n",
    "print(\"Predicted offensive but actually reappropriate:\\n\")\n",
    "for i, sentence in enumerate(fn_sentences):\n",
    "    print(i)\n",
    "    print(sentence)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# save to CSV with space between them\n",
    "pd.DataFrame(fn_sentences, columns=[\"sentence\"]).to_csv(\"error_analysis/set_fit_pipeline/false_negatives_it.csv\", index=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad7dc082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted reappropriate but actually offensive:\n",
      "\n",
      "0\n",
      "Tutti i vostri \"frocio\", mi aprivano un varco verso le camere a gas. Mi hanno ucciso ma IO HO POTUTO LOTTARE, loro no. Anche per questo serve una legge contro l'omofobia\n",
      "\n",
      "#omocausto #GiornataDellaMemoria2021 @USER\n",
      "\n",
      "\n",
      "1\n",
      "Lo ripeto: i froci fanno vomitare e i loro pride di merda altrettanto visto che la domenica vorrei dormire e mi svegliano con Lady Gaga a palla\n",
      "\n",
      "\n",
      "2\n",
      "Ieri sono uscito con una tuta arcobaleno e un tipo mi fa \"frocio se vuoi ti faccio conoscere qualcuno che te lo mette al culo\" e all'inizio non l'ho presa benissimo\n",
      "\n",
      "\n",
      "3\n",
      "Per inciso: il â€œfrocio di m.â€ era il paziente che stava operando e giÃ  in anestesia totale #omofobia #7luglio\n",
      "\n",
      "â€œGuardate se devo operare sto frocio di m...â€: sospeso primario nel Varesotto URL\n",
      "\n",
      "\n",
      "4\n",
      "#Morisi se sei finocchio di dx non sei garantito dal ddl zan mentre se sei di sx e fai il porco nei gaypride o spacci a cielo aperto e tutto regolare\n",
      "\n",
      "\n",
      "5\n",
      "Ma lultimo che \"froci\" e subito dopo \"LGbt 4ever e bla bla bla ğŸ˜œğŸ˜œğŸ˜œ\" haha so quirky haha I'm soooo random ğŸ¤£ğŸ¤£ğŸ¤£ la gente (non) ride alle mie battute!! Haha perchÃ© in realtÃ  sono... INSULTI ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ğŸ˜œğŸ˜œğŸ˜œğŸ˜ğŸ’¯ğŸ”ğŸ’¯ğŸ”\n",
      "\n",
      "\n",
      "6\n",
      "Tutti con le foto arcobaleno e poi appena vedono un ragazzo effemminato esclamano \"talÃª ddu  frocio\"\n",
      "Vergognatevi \n",
      "#LoveIsLove \n",
      "#lovewins \n",
      "â¤ï¸ğŸ§¡ğŸ’›ğŸ’šğŸ’œğŸ’™\n",
      "\n",
      "\n",
      "7\n",
      "I FROCI COMUNISTI ARCOBALENO...SCRIVONO... ANDRÃ€ TUTTO BENE...dovrebbero scrivre: ANDRA' TUTTO PENE...CONSIDERATO CHE CE L' HANNO MES ....IN KUL.\n",
      "\n",
      "\n",
      "8\n",
      "come quando â€œma frocio non mi sembra un insultoâ€ amore mio se io parte della comunitÃ  lgbtqia ti dico che lo Ã¨, lo Ã¨. fai parte della community? no? e allora che cazzo parli a fare\n",
      "\n",
      "\n",
      "9\n",
      "@USER La pensassero tutte come te...ne avremmo comunque di finocchi ma \"con l'orgoglio\" no eh. E gli etero allora saremmo tutti coglioni che non facciano \"l'etero prude\"??? URL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indices of false positives : predicted reappropriate but actually offensive\n",
    "fp_indices = np.where((y_true == 0) & (y_pred == 1))[0]\n",
    "\n",
    "fp_sentences = [dataset_it[\"test\"][i]['text'] for i in fp_indices]\n",
    "\n",
    "print(\"Predicted reappropriate but actually offensive:\\n\")\n",
    "for i, sentence in enumerate(fp_sentences):\n",
    "    print(i)\n",
    "    print(sentence)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# save to CSV with space between them\n",
    "pd.DataFrame(fp_sentences, columns=[\"sentence\"]).to_csv(\"error_analysis/set_fit_pipeline/false_positives_it.csv\", index=True, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-pride",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
